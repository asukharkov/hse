{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0wBrTmoRW97n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym.core import ObservationWrapper\n",
        "from gym.spaces import Box\n",
        "from scipy.misc import imresize\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import transform\n",
        "from keras.layers import Conv2D, Dense, Flatten, InputLayer\n",
        "import os\n",
        "from IPython import display\n",
        "import random\n",
        "from gym.core import Wrapper\n",
        "from tqdm import trange\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import DataFrame\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rMr165-IW978",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f76cf8fc-1edd-41ee-8f41-e066c2d3940a"
      },
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "alGDYTtiW98M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class PreprocessAtari(ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        ObservationWrapper.__init__(self, env)\n",
        "        self.img_size = (64, 64, 1)\n",
        "        self.observation_space = Box(0.0, 1.0, self.img_size)\n",
        "\n",
        "    def _observation(self, img):    \n",
        "        img = rgb2gray(img)\n",
        "        img = img[4:-15,5:-5]\n",
        "        img = img / 255.0\n",
        "        img = transform.resize(img, [self.img_size[0], self.img_size[1], self.img_size[2]])\n",
        "        \n",
        "        return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dy-h4xsEW98a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FrameBuffer(Wrapper):\n",
        "    def __init__(self, env, n_frames=4, dim_order='tensorflow'):\n",
        "        super(FrameBuffer, self).__init__(env)\n",
        "        self.dim_order = dim_order\n",
        "        if dim_order == 'tensorflow':\n",
        "            height, width, n_channels = env.observation_space.shape\n",
        "            obs_shape = [height, width, n_channels * n_frames]\n",
        "        elif dim_order == 'pytorch':\n",
        "            n_channels, height, width = env.observation_space.shape\n",
        "            obs_shape = [n_channels * n_frames, height, width]\n",
        "        else:\n",
        "            raise ValueError('dim_order should be \"tensorflow\" or \"pytorch\", got {}'.format(dim_order))\n",
        "        self.observation_space = Box(0.0, 1.0, obs_shape)\n",
        "        self.framebuffer = np.zeros(obs_shape, 'float32')\n",
        "        \n",
        "    def reset(self):\n",
        "        self.framebuffer = np.zeros_like(self.framebuffer)\n",
        "        self.update_buffer(self.env.reset())\n",
        "        return self.framebuffer\n",
        "    \n",
        "    def step(self, action):\n",
        "        new_img, reward, done, info = self.env.step(action)\n",
        "        self.update_buffer(new_img)\n",
        "        return self.framebuffer, reward, done, info\n",
        "    \n",
        "    def update_buffer(self, img):\n",
        "        if self.dim_order == 'tensorflow':\n",
        "            offset = self.env.observation_space.shape[-1]\n",
        "            axis = -1\n",
        "            cropped_framebuffer = self.framebuffer[:,:,:-offset]\n",
        "        elif self.dim_order == 'pytorch':\n",
        "            offset = self.env.observation_space.shape[0]\n",
        "            axis = 0\n",
        "            cropped_framebuffer = self.framebuffer[:-offset]\n",
        "        self.framebuffer = np.concatenate([img, cropped_framebuffer], axis = axis)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "goMnMaoSW98o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "36ced20a-7eda-411b-80a1-c7808a4d657e"
      },
      "cell_type": "code",
      "source": [
        "def make_env():\n",
        "    env = gym.make(\"BreakoutDeterministic-v4\")\n",
        "    env = PreprocessAtari(env)\n",
        "    env = FrameBuffer(env, n_frames=4, dim_order='tensorflow')\n",
        "    return env\n",
        "\n",
        "env = make_env()\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
            "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hmapQpo6W98-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "4b71263b-1a96-4d4d-a1b6-9941bfc126f1"
      },
      "cell_type": "code",
      "source": [
        "for _ in range(50):\n",
        "    obs, _, _, _ = env.step(env.action_space.sample())\n",
        "\n",
        "plt.title(\"Game image\")\n",
        "plt.imshow(env.render(\"rgb_array\"))\n",
        "plt.show()\n",
        "plt.title(\"Agent observation (4 frames left to right)\")\n",
        "plt.imshow(obs.transpose([0, 2, 1]).reshape([state_dim[0], -1]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMsAAAEHCAYAAAAAprJIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRAIpLCKBFBaRQAqLSKD/B+6pEkhfBldLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcd805c4b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAACCCAYAAABfNJOZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpJRKuAiIhn1/4HvhBzmY0RTAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vNMDE0voW99W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "331c402b-331e-41c5-bb04-818985802a55"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oXuChKjXW99r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, name, state_shape, n_actions, epsilon=0, reuse=False):\n",
        "        \"\"\"A simple DQN agent\"\"\"\n",
        "        with tf.variable_scope(name, reuse=reuse):\n",
        "            self.network = keras.models.Sequential()\n",
        "            self.network.add(Conv2D(16, (3, 3), strides=2, activation='relu', input_shape=state_shape))\n",
        "            self.network.add(Conv2D(32, (3, 3), strides=2, activation='relu'))\n",
        "            self.network.add(Conv2D(64, (3, 3), strides=2, activation='relu'))\n",
        "            self.network.add(Flatten())\n",
        "            self.network.add(Dense(256, activation='relu'))\n",
        "            self.network.add(Dense(n_actions, activation='linear'))\n",
        "            self.state_t = tf.placeholder('float32', [None, ] + list(state_shape))\n",
        "            self.qvalues_t = self.get_symbolic_qvalues(self.state_t)\n",
        "        self.weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=name)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def get_symbolic_qvalues(self, state_t):\n",
        "        qvalues = self.network(state_t)\n",
        "        assert tf.is_numeric_tensor(qvalues) and qvalues.shape.ndims == 2, \\\n",
        "            \"please return 2d tf tensor of qvalues [you got %s]\" % repr(qvalues)\n",
        "        assert int(qvalues.shape[1]) == n_actions\n",
        "        return qvalues\n",
        "\n",
        "    def get_qvalues(self, state_t):\n",
        "        sess = tf.get_default_session()\n",
        "        return sess.run(self.qvalues_t, {self.state_t: state_t})\n",
        "\n",
        "    def sample_actions(self, qvalues):\n",
        "        epsilon = self.epsilon\n",
        "        batch_size, n_actions = qvalues.shape\n",
        "        random_actions = np.random.choice(n_actions, size=batch_size)\n",
        "        best_actions = qvalues.argmax(axis=-1)\n",
        "        should_explore = np.random.choice([0, 1], batch_size, p=[1-epsilon, epsilon])\n",
        "        return np.where(should_explore, random_actions, best_actions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fjFhHYCXW9-E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "agent = DQNAgent(\"dqn_agent\", state_dim, n_actions, epsilon=0.5)\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KgpIqJ3bW9-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(env, agent, n_games=1, greedy=False, t_max=10000):\n",
        "    rewards = []\n",
        "    for _ in range(n_games):\n",
        "        s = env.reset()\n",
        "        reward = 0\n",
        "        for _ in range(t_max):\n",
        "            qvalues = agent.get_qvalues([s])\n",
        "            action = qvalues.argmax(\n",
        "                axis=-1)[0] if greedy else agent.sample_actions(qvalues)[0]\n",
        "            s, r, done, _ = env.step(action)\n",
        "            reward += r\n",
        "            if done:\n",
        "                break\n",
        "        rewards.append(reward)\n",
        "    return np.mean(rewards)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nm1GQ2FkW9-o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ReplayBuffer(object):\n",
        "    def __init__(self, size):\n",
        "        self._storage = []\n",
        "        self._maxsize = size\n",
        "        self._current = 0\n",
        "        self._flag = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._storage)\n",
        "\n",
        "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
        "        data = (obs_t, action, reward, obs_tp1, done)\n",
        "        if self._flag:\n",
        "            self._storage[self._current] = data\n",
        "        else:\n",
        "            self._storage.append(data)\n",
        "        self._current += 1\n",
        "        if self._current == self._maxsize:\n",
        "            self._flag = 1\n",
        "        self._current %= self._maxsize\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        idxes = [random.randint(0, self.__len__() - 1) for _ in range(batch_size)]\n",
        "        obs_batch, act_batch, rew_batch, next_obs_batch, done_mask = [], [], [], [], []\n",
        "        for i in idxes:\n",
        "            data = self._storage[i]\n",
        "            obs, act, rew, next_obs, done = data\n",
        "            obs_batch.append(np.array(obs, copy=False))\n",
        "            act_batch.append(np.array(act, copy=False))\n",
        "            rew_batch.append(rew)\n",
        "            next_obs_batch.append(np.array(next_obs, copy=False))\n",
        "            done_mask.append(done)\n",
        "        return np.array(obs_batch), np.array(act_batch), np.array(rew_batch), np.array(next_obs_batch), np.array(done_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zBo1iUGJW9-6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def play_and_record(agent, env, exp_replay, n_steps=1):\n",
        "    s = env.framebuffer\n",
        "    reward = 0\n",
        "    for i in range(n_steps):\n",
        "        qvalues = agent.get_qvalues([s])\n",
        "        action = agent.sample_actions(qvalues)[0]\n",
        "        next_s, done, rew, _ = env.step(action)\n",
        "        reward += rew\n",
        "        exp_replay.add(s, action, rew, next_s, done)\n",
        "        s = next_s\n",
        "        if done:\n",
        "            s = env.reset()\n",
        "    return reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YYZgDPRFW9_J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_network = DQNAgent(\"target_network\", state_dim, n_actions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LFgkuBt1W9_Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_weigths_into_target_network(agent, target_network):\n",
        "    assigns = []\n",
        "    for w_agent, w_target in zip(agent.weights, target_network.weights):\n",
        "        assigns.append(tf.assign(w_target, w_agent, validate_shape=True))\n",
        "    return assigns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eFORrJChW-AI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85b19085-2360-4340-fc9d-fa7e4cddcc2b"
      },
      "cell_type": "code",
      "source": [
        "copy_step = load_weigths_into_target_network(agent, target_network)\n",
        "sess.run(copy_step)\n",
        "sess.run([tf.assert_equal(w, w_target) for w, w_target in zip(agent.weights, target_network.weights)])\n",
        "print(\"It works!\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It works!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1uq5MdJJW-AZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "obs_ph = tf.placeholder(tf.float32, shape=(None,) + state_dim)\n",
        "actions_ph = tf.placeholder(tf.int32, shape=[None])\n",
        "rewards_ph = tf.placeholder(tf.float32, shape=[None])\n",
        "next_obs_ph = tf.placeholder(tf.float32, shape=(None,) + state_dim)\n",
        "is_done_ph = tf.placeholder(tf.float32, shape=[None])\n",
        "is_not_done = 1 - is_done_ph\n",
        "gamma = 0.99"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PxcKr9gwW-Ak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "current_qvalues = agent.get_symbolic_qvalues(obs_ph)\n",
        "current_action_qvalues = tf.reduce_sum(tf.one_hot(actions_ph, n_actions) * current_qvalues, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vufzaIE6W-At",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "next_qvalues_target = target_network.get_symbolic_qvalues(next_obs_ph)\n",
        "next_state_values_target = tf.reduce_max(next_qvalues_target, axis=-1)\n",
        "reference_qvalues = rewards_ph + gamma * next_state_values_target * is_not_done\n",
        "td_loss = (current_action_qvalues - reference_qvalues) ** 2\n",
        "td_loss = tf.reduce_mean(td_loss)\n",
        "train_step = tf.train.AdamOptimizer(1e-3).minimize(td_loss, var_list=agent.weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FV-hYpkIW-A3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-rRPNZ7W-A-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "moving_average = lambda x, span=100, **kw: DataFrame(\n",
        "    {'x': np.asarray(x)}).x.ewm(span=span, **kw).mean().values\n",
        "%matplotlib inline\n",
        "\n",
        "mean_rw_history = []\n",
        "td_loss_history = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wX8NsZKXW-BE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "outputId": "562f1d92-4fa9-4181-8d17-3415ff13e328"
      },
      "cell_type": "code",
      "source": [
        "exp_replay = ReplayBuffer(10**5)\n",
        "play_and_record(agent, env, exp_replay, n_steps=10000)\n",
        "\n",
        "def sample_batch(exp_replay, batch_size):\n",
        "    obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(batch_size)\n",
        "    return {\n",
        "        obs_ph: obs_batch, actions_ph: act_batch, rewards_ph: reward_batch,\n",
        "        next_obs_ph: next_obs_batch, is_done_ph: is_done_batch\n",
        "    }"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-b727f278ffda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp_replay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplayBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplay_and_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_replay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_replay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mobs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_obs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_replay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-336804a071d5>\u001b[0m in \u001b[0;36mplay_and_record\u001b[0;34m(agent, env, exp_replay, n_steps)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mqvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mnext_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mexp_replay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-1b69b778f826>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mnew_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframebuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mObservationWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/atari_py/ale_python_interface.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0male_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MpCe9gWrW-BL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in trange(10**5):\n",
        "    play_and_record(agent, env, exp_replay, 10)\n",
        "    _, loss_t = sess.run([train_step, td_loss], sample_batch(exp_replay, batch_size=64))\n",
        "    td_loss_history.append(loss_t)\n",
        "    if i % 500 == 0:\n",
        "        sess.run(copy_step)\n",
        "        agent.epsilon = max(agent.epsilon * 0.99, 0.01)\n",
        "        mean_rw_history.append(evaluate(make_env(), agent, n_games=3))\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print(\"buffer size = %i, epsilon = %.5f\" %\n",
        "              (len(exp_replay), agent.epsilon))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"mean reward per game\")\n",
        "        plt.plot(mean_rw_history)\n",
        "        plt.grid()\n",
        "        assert not np.isnan(loss_t)\n",
        "        plt.figure(figsize=[12, 4])\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"TD loss history (moving average)\")\n",
        "        plt.plot(moving_average(np.array(td_loss_history), span=100, min_periods=100))\n",
        "        plt.grid()\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSz1pY6_W-BW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert np.mean(mean_rw_history[-10:]) > 10.\n",
        "print(\"That's good enough for tutorial.\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}